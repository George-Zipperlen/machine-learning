{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore how many PCA Components to Keep and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways after running this notebook:\n",
    "1. The accurace gain by searching over a larger range of n_components seems to be small (~1%-2% gain in testing AUROC on average), even when the range of n_components is selected for each query based on a heuristic around class balance.\n",
    "2. There is a similar accurace gain when only the largest value in the range is used \n",
    "2. There is a larger performance gain if the l1_ratio is changed from 0.15 to 0 and the range of alpha is expanded (~5%-7% gain in testing AUROC on average) there isn't much performance gain if these parameters are changed independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purpose__\n",
    "\n",
    "As described in issue #106 (https://github.com/cognoma/machine-learning/issues/106), searching over a large range of n_components (number of PCA components) causes issues with both speed and memory and may also cause issues with overfitting. This notebook is an attempt to explore the relationship between the number of components returned by PCA, the other hyperparameters and classifier performance (AUROC). Ideally, we will be able to automatically select a range of n_components to search across based on the specifics of the query. The assumption is that for the lower number of positive samples (and/or the less total samples)... the less n-components to include (i.e. a query with only 40 positive samples would use a classifer that does GridSearchCV with n_components = [30, 40, 50] whereas a query with 1,000 positive samples would use a classifier that does GridSearchCV with n_components = [100, 200, 300] _just random numbers for purpose of illustration_). This notebook attempts to provide some basis for selecting the range of n_components.\n",
    "\n",
    "\n",
    "__Assumptions/Notes:__\n",
    "\n",
    "This notebook differs from the current classifier in a number of ways including:\n",
    "1. In this notebook, PCA is performed on the entire training set prior to cross-validation rather than performed on each individual cross-validation split. This is done for simplicity and to save time and memory.\n",
    "2. In this notebook, the covariates data is not used (for now at least).\n",
    "\n",
    "\n",
    "__To Do:__\n",
    "\n",
    "1. Evaluate queries that only use a subset of diseases or a single disease.\n",
    "2. Try to include the covariates data and see how that affects things.\n",
    "3. Some additional evaluation and... select a final setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "1. Imports, constants and load the data\n",
    "2. Test Train split and perform PCA\n",
    "3. Build the querry set\n",
    "4. Evaluate queries with all samples (i.e. all diseases) and varying number of positives\n",
    " - a. Define some helper functions\n",
    " - b. See how the parameters are related using the current setup\n",
    " - c. Evaluate how changing some of the parameters effects performance\n",
    "5. TO DO: Evaluate queries that only use a subset of diseases or a single disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, constants and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from dask_searchcv import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOMSEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the data\n",
    "try: \n",
    "    path = os.path.join('download', 'expression-matrix.pkl')\n",
    "    X = pd.read_pickle(path)\n",
    "except:\n",
    "    path = os.path.join('download', 'expression-matrix.tsv.bz2')\n",
    "    X = pd.read_table(path, index_col=0)\n",
    "\n",
    "try:\n",
    "    path = os.path.join('download', 'mutation-matrix.pkl')\n",
    "    y = pd.read_pickle(path)\n",
    "except:\n",
    "    path = os.path.join('download', 'mutation-matrix.tsv.bz2')\n",
    "    y = pd.read_table(path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Train split and perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Train split\n",
    "X_train, X_test, y_train_allgenes, y_test_allgenes = train_test_split(X, y, test_size=0.2, random_state=RANDOMSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components = 1000, random_state = RANDOMSEED)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train = pca.transform(X_train_scaled)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the query set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of genes to iterate over (from brankaj's notebook: \n",
    "# https://github.com/cognoma/machine-learning/blob/master/explore/Classifier_results-different_genes.ipynb)\n",
    "genes_LungCancer = {\n",
    "    '207': 'AKT1', \n",
    "    '238': 'ALK',  \n",
    "    '673': 'BRAF', \n",
    "    '4921':'DDR2',\n",
    "    '1956':'EGFR',\n",
    "    '2064':'ERBB2',\n",
    "    '3845':'KRAS',\n",
    "    '5604':'MAP2K1',\n",
    "    '4893':'NRAS',\n",
    "    '5290':'PIK3CA',\n",
    "    '5728':'PTEN',\n",
    "    '5979':'RET',\n",
    "    # '6016':'RIT1', (removed because too few positives)\n",
    "    '6098':'ROS1',\n",
    "}\n",
    "\n",
    "genes_TumorSuppressors = {\n",
    "    '324': 'APC',  \n",
    "    '672': 'BRCA1',  \n",
    "    '675': 'BRCA2',\n",
    "    '1029':'CDKN2A',\n",
    "    '1630':'DCC',\n",
    "    '4089':'SMAD4',\n",
    "    '4087':'SMAD2',\n",
    "    '4221':'MEN1',\n",
    "    '4763':'NF1',\n",
    "    '4771':'NF2',\n",
    "    '7157':'TP53', \n",
    "    '5728':'PTEN', \n",
    "    '5925':'RB1',\n",
    "    '7428':'VHL',\n",
    "    '7486':'WRN',\n",
    "    '7490':'WT1',\n",
    "}\n",
    "\n",
    "genes_Oncogenes = {\n",
    "    #'5155':'PDGFB', #growth factor (removed because too few positives)\n",
    "    '5159':'PDGFRB', #growth factor \n",
    "    '3791':'KDR', #receptor tyrosine kinases\n",
    "    '25':'ABL1', #Cytoplasmic tyrosine kinases\n",
    "    '6714':'SRC', #Cytoplasmic tyrosine kinases\n",
    "    '5894':'RAF1',#cytoplasmic serine kinases\n",
    "    '3265':'HRAS',#regulatory GTPases\n",
    "    '4609':'MYC',#Transcription factors\n",
    "    #'2353':'FOS',#Transcription factors (removed because too few positives)\n",
    "    \n",
    "}\n",
    "\n",
    "list_of_genes = (list(genes_LungCancer.keys()) + list(genes_TumorSuppressors.keys()) + \n",
    "    list(genes_Oncogenes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_genes_positives = []\n",
    "for gene in list_of_genes:\n",
    "    y_temp = y_train_allgenes[gene]\n",
    "    list_of_genes_positives.append(y_temp.value_counts(True)[1]*len(y_train_allgenes))\n",
    "list_of_genes = [gene for _,gene in sorted(zip(list_of_genes_positives, list_of_genes))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate queries with all samples (i.e. all diseases) and varying number of positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a. Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variance_scorer(x, y):\n",
    "    \"\"\"    \n",
    "    Get the variance for each column of X.\n",
    "    \n",
    "    Because principal components have decreasing variance\n",
    "    (i.e. PC4 has less variance than PC3 which has less variance\n",
    "    than PC2 etc.), we can use this function in SelectKBest to select\n",
    "    only the top X number of principal components.\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = [np.var(column) for column in x.T]\n",
    "    return scores, np.array([np.NaN]*len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(X_train, X_test,\n",
    "                        y, y_train_allgenes, y_test_allgenes,\n",
    "                        list_of_genes,\n",
    "                        set_k_range, k_function,\n",
    "                        alpha_range, \n",
    "                        l1_ratio):\n",
    "    \n",
    "    ''' Run a classifier setup on a set of queries.\n",
    "    \n",
    "        Loop through each query; train and test the classifier using the\n",
    "        hyperparameters input as parameters; populate the metrics dictionary\n",
    "        with some metrics of which parameters were selected and how well\n",
    "        the classifier did for that query.\n",
    "    '''\n",
    "    \n",
    "    # A dictionary to hold the performance metrics.\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    # Loop through each query; train and test the classifer; populate the metrics dictionary.\n",
    "    for gene in list_of_genes:\n",
    "        \n",
    "        # Train and test the classifier.\n",
    "        \n",
    "        y_gene = y[gene]\n",
    "        y_train = y_train_allgenes[gene]\n",
    "        y_test = y_test_allgenes[gene]\n",
    "        num_positives = int(y_gene.value_counts(True)[1]*len(y_gene))\n",
    "        if set_k_range:\n",
    "            k_range = set_k_range\n",
    "        else:\n",
    "            k_range = k_function(num_positives)     \n",
    "        # Parameter Sweep for Hyperparameters\n",
    "        param_grid = {\n",
    "            'select__k': k_range,\n",
    "            'classify__loss': ['log'],\n",
    "            'classify__penalty': ['elasticnet'],\n",
    "            'classify__alpha': alpha_range,\n",
    "            'classify__l1_ratio': l1_ratio,\n",
    "        }\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('select', SelectKBest(variance_scorer)),\n",
    "            ('classify', SGDClassifier(random_state=RANDOMSEED, class_weight='balanced'))\n",
    "        ])\n",
    "        cv_pipeline = GridSearchCV(estimator=pipeline, \n",
    "                                   param_grid=param_grid,\n",
    "                                   n_jobs=1, \n",
    "                                   scoring='roc_auc')\n",
    "        cv_pipeline.fit(X=X_train, y=y_train)\n",
    "        y_pred_train = cv_pipeline.decision_function(X_train)\n",
    "        y_pred_test = cv_pipeline.decision_function(X_test)\n",
    "        # Get ROC info.\n",
    "        def get_threshold_metrics(y_true, y_pred):\n",
    "            roc_columns = ['fpr', 'tpr', 'threshold']\n",
    "            roc_items = zip(roc_columns, roc_curve(y_true, y_pred))\n",
    "            roc_df = pd.DataFrame.from_items(roc_items)\n",
    "            auroc = roc_auc_score(y_true, y_pred)\n",
    "            return {'auroc': auroc, 'roc_df': roc_df}\n",
    "        metrics_train = get_threshold_metrics(y_train, y_pred_train)\n",
    "        metrics_test = get_threshold_metrics(y_test, y_pred_test)\n",
    "\n",
    "        # Populate the metrics dictionary.\n",
    "\n",
    "        # Get metrics for the classifier.\n",
    "        overfit = metrics_train['auroc'] - metrics_test['auroc']\n",
    "        # Understand how the parameter grid worked... any params at the edge?\n",
    "        if cv_pipeline.best_params_['select__k'] == min(param_grid['select__k']):\n",
    "            n_comp_status = 'min'\n",
    "        elif cv_pipeline.best_params_['select__k'] == max(param_grid['select__k']):\n",
    "            n_comp_status = 'max'\n",
    "        else:\n",
    "            n_comp_status = 'OK'\n",
    "        if cv_pipeline.best_params_['classify__alpha'] == min(param_grid['classify__alpha']):\n",
    "            alpha_status = 'min'\n",
    "        elif cv_pipeline.best_params_['classify__alpha'] == max(param_grid['classify__alpha']):\n",
    "            alpha_status = 'max'\n",
    "        else:\n",
    "            alpha_status = 'OK'\n",
    "        metrics = {'num_positive': num_positives,\n",
    "                   'train_auroc': metrics_train['auroc'], \n",
    "                   'test_auroc': metrics_test['auroc'],\n",
    "                   'n_components': cv_pipeline.best_params_['select__k'], \n",
    "                   'alpha': cv_pipeline.best_params_['classify__alpha'],\n",
    "                   'overfit': overfit,\n",
    "                   'n_comp_status': n_comp_status,\n",
    "                   'alpha_status': alpha_status\n",
    "                  }\n",
    "        # Add the metrics to the dictonary.\n",
    "        metrics_dict[gene] = metrics\n",
    "    # Change the metrics dict into a formatted pandas dataframe.\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    metrics_df = metrics_df.T\n",
    "    metrics_df.sort_values(by='num_positive', ascending=True, inplace=True)\n",
    "    metrics_df = metrics_df[['num_positive', 'n_components','n_comp_status', 'alpha', 'alpha_status','train_auroc', 'test_auroc', 'overfit']]\n",
    "    \n",
    "    return(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stats(metrics_df, metrics_df_tocompare = None, verbose = True):\n",
    "    if verbose:\n",
    "        display(metrics_df)\n",
    "    # Summary for metrics_df    \n",
    "    metrics_df.loc['mean'] = metrics_df.mean()\n",
    "    metrics_df.loc['median'] = metrics_df.median()\n",
    "    metrics_df_summary = metrics_df.loc[['mean', 'median']]\n",
    "    metrics_df_summary = metrics_df_summary[['num_positive', 'n_components', 'alpha', 'train_auroc', 'test_auroc','overfit']]\n",
    "    display(metrics_df_summary)\n",
    "    if metrics_df_tocompare is not None:\n",
    "        # Summary for metrics_df_tocompare\n",
    "        metrics_df_tocompare.loc['mean'] = metrics_df_tocompare.mean()\n",
    "        metrics_df_tocompare.loc['median'] = metrics_df_tocompare.median()\n",
    "        metrics_df_to_compare_summary = metrics_df_tocompare.loc[['mean', 'median']]\n",
    "        # Evaluate the improvement\n",
    "        mean_testing_auroc_improvement = metrics_df_summary['test_auroc']['mean'] - metrics_df_to_compare_summary['test_auroc']['mean']\n",
    "        median_testing_auroc_improvement = metrics_df_summary['test_auroc']['median'] - metrics_df_to_compare_summary['test_auroc']['median']\n",
    "        mean_overfit_reduction = metrics_df_to_compare_summary['overfit']['mean'] - metrics_df_summary['overfit']['mean']\n",
    "        median_overfit_reduction = metrics_df_to_compare_summary['overfit']['median'] - metrics_df_summary['overfit']['median']\n",
    "        print('Mean testing Auroc improved by {:.2f}%'.format(mean_testing_auroc_improvement*100))\n",
    "        print('Median testing Auroc improved by {:.2f}%'.format(median_testing_auroc_improvement*100))\n",
    "        print('Mean overfitting reduced by {:.1f}%'.format(mean_overfit_reduction*100))\n",
    "        print('Median overfitting reduced by {:.1f}%'.format(median_overfit_reduction*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b. See how the parameters are related using the current setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_comp_status</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_status</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.689502</td>\n",
       "      <td>0.564129</td>\n",
       "      <td>0.125373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.744421</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.301239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.395891</td>\n",
       "      <td>0.232128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.75881</td>\n",
       "      <td>0.672984</td>\n",
       "      <td>0.0858264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.757118</td>\n",
       "      <td>0.733031</td>\n",
       "      <td>0.0240868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.907156</td>\n",
       "      <td>0.508406</td>\n",
       "      <td>0.39875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.726585</td>\n",
       "      <td>0.606066</td>\n",
       "      <td>0.12052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.565093</td>\n",
       "      <td>0.164721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.871729</td>\n",
       "      <td>0.767271</td>\n",
       "      <td>0.104459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.001</td>\n",
       "      <td>min</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.54043</td>\n",
       "      <td>0.189474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.650832</td>\n",
       "      <td>0.487645</td>\n",
       "      <td>0.163187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.767125</td>\n",
       "      <td>0.628415</td>\n",
       "      <td>0.138711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>104</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.561093</td>\n",
       "      <td>0.0948058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>112</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.796264</td>\n",
       "      <td>0.869321</td>\n",
       "      <td>-0.0730568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.001</td>\n",
       "      <td>min</td>\n",
       "      <td>0.699525</td>\n",
       "      <td>0.548448</td>\n",
       "      <td>0.151076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.843235</td>\n",
       "      <td>0.782702</td>\n",
       "      <td>0.0605324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>135</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.001</td>\n",
       "      <td>min</td>\n",
       "      <td>0.972091</td>\n",
       "      <td>0.966344</td>\n",
       "      <td>0.00574742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.62016</td>\n",
       "      <td>-0.00623589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>138</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.001</td>\n",
       "      <td>min</td>\n",
       "      <td>0.658907</td>\n",
       "      <td>0.540739</td>\n",
       "      <td>0.118167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>153</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.827951</td>\n",
       "      <td>0.7313</td>\n",
       "      <td>0.0966513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>169</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>0.62616</td>\n",
       "      <td>0.0745953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.892832</td>\n",
       "      <td>-0.0389552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>188</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.774783</td>\n",
       "      <td>0.742351</td>\n",
       "      <td>0.0324319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>231</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.820551</td>\n",
       "      <td>0.760429</td>\n",
       "      <td>0.0601219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>235</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.734492</td>\n",
       "      <td>0.673222</td>\n",
       "      <td>0.0612695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>237</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.620436</td>\n",
       "      <td>0.645226</td>\n",
       "      <td>-0.0247902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>263</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.820783</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.0607777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>274</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.813853</td>\n",
       "      <td>0.825692</td>\n",
       "      <td>-0.0118388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>279</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.755646</td>\n",
       "      <td>0.716968</td>\n",
       "      <td>0.0386786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>316</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.704367</td>\n",
       "      <td>0.708792</td>\n",
       "      <td>-0.00442577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>423</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.851976</td>\n",
       "      <td>0.84182</td>\n",
       "      <td>0.0101554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.927095</td>\n",
       "      <td>-0.0100076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>527</td>\n",
       "      <td>50</td>\n",
       "      <td>min</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.928241</td>\n",
       "      <td>0.915307</td>\n",
       "      <td>0.012934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>853</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.802165</td>\n",
       "      <td>0.799111</td>\n",
       "      <td>0.00305423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>2587</td>\n",
       "      <td>100</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>0.893914</td>\n",
       "      <td>0.88026</td>\n",
       "      <td>0.0136536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_positive n_components n_comp_status  alpha alpha_status train_auroc  \\\n",
       "6714           34           50           min   0.01           OK    0.689502   \n",
       "4609           37           50           min   0.01           OK    0.744421   \n",
       "207            38           50           min   0.01           OK    0.628019   \n",
       "5894           42           50           min      1          max     0.75881   \n",
       "4087           48          100           max   0.01           OK    0.757118   \n",
       "5604           55          100           max    0.1           OK    0.907156   \n",
       "4221           57           50           min   0.01           OK    0.726585   \n",
       "7490           58           50           min   0.01           OK    0.729814   \n",
       "4771           79          100           max   0.01           OK    0.871729   \n",
       "25             80          100           max  0.001          min    0.729904   \n",
       "4921           85          100           max      1          max    0.650832   \n",
       "5159           91          100           max    0.1           OK    0.767125   \n",
       "7486          104           50           min    0.1           OK    0.655899   \n",
       "3265          112          100           max      1          max    0.796264   \n",
       "5979          117          100           max  0.001          min    0.699525   \n",
       "4893          117          100           max    0.1           OK    0.843235   \n",
       "7428          135          100           max  0.001          min    0.972091   \n",
       "672           136          100           max      1          max    0.613924   \n",
       "238           138           50           min  0.001          min    0.658907   \n",
       "2064          153          100           max    0.1           OK    0.827951   \n",
       "3791          169           50           min      1          max    0.700755   \n",
       "4089          185          100           max      1          max    0.853877   \n",
       "6098          188          100           max      1          max    0.774783   \n",
       "1956          231           50           min      1          max    0.820551   \n",
       "1630          235          100           max      1          max    0.734492   \n",
       "675           237          100           max      1          max    0.620436   \n",
       "5925          263           50           min      1          max    0.820783   \n",
       "1029          274           50           min      1          max    0.813853   \n",
       "5728          279          100           max      1          max    0.755646   \n",
       "4763          316          100           max      1          max    0.704367   \n",
       "324           423           50           min      1          max    0.851976   \n",
       "673           500          100           max      1          max    0.917088   \n",
       "3845          527           50           min    0.1           OK    0.928241   \n",
       "5290          853          100           max      1          max    0.802165   \n",
       "7157         2587          100           max      1          max    0.893914   \n",
       "\n",
       "     test_auroc     overfit  \n",
       "6714   0.564129    0.125373  \n",
       "4609   0.443182    0.301239  \n",
       "207    0.395891    0.232128  \n",
       "5894   0.672984   0.0858264  \n",
       "4087   0.733031   0.0240868  \n",
       "5604   0.508406     0.39875  \n",
       "4221   0.606066     0.12052  \n",
       "7490   0.565093    0.164721  \n",
       "4771   0.767271    0.104459  \n",
       "25      0.54043    0.189474  \n",
       "4921   0.487645    0.163187  \n",
       "5159   0.628415    0.138711  \n",
       "7486   0.561093   0.0948058  \n",
       "3265   0.869321  -0.0730568  \n",
       "5979   0.548448    0.151076  \n",
       "4893   0.782702   0.0605324  \n",
       "7428   0.966344  0.00574742  \n",
       "672     0.62016 -0.00623589  \n",
       "238    0.540739    0.118167  \n",
       "2064     0.7313   0.0966513  \n",
       "3791    0.62616   0.0745953  \n",
       "4089   0.892832  -0.0389552  \n",
       "6098   0.742351   0.0324319  \n",
       "1956   0.760429   0.0601219  \n",
       "1630   0.673222   0.0612695  \n",
       "675    0.645226  -0.0247902  \n",
       "5925   0.760005   0.0607777  \n",
       "1029   0.825692  -0.0118388  \n",
       "5728   0.716968   0.0386786  \n",
       "4763   0.708792 -0.00442577  \n",
       "324     0.84182   0.0101554  \n",
       "673    0.927095  -0.0100076  \n",
       "3845   0.915307    0.012934  \n",
       "5290   0.799111  0.00305423  \n",
       "7157    0.88026   0.0136536  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>80</td>\n",
       "      <td>0.533543</td>\n",
       "      <td>0.77205</td>\n",
       "      <td>0.692798</td>\n",
       "      <td>0.0792519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>100</td>\n",
       "      <td>0.766771</td>\n",
       "      <td>0.762968</td>\n",
       "      <td>0.700795</td>\n",
       "      <td>0.0610236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc    overfit\n",
       "mean        256.657           80  0.533543     0.77205   0.692798  0.0792519\n",
       "median          137          100  0.766771    0.762968   0.700795  0.0610236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_df_current_setup = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [50, 100],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df_current_setup, metrics_df_tocompare = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAKaCAYAAABiGdI1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERGx2v8Byc0k+rtOSkgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f801b2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how some of these metrics/parameters might be related\n",
    "metrics_df_for_correlations = metrics_df_current_setup[['num_positive', 'n_components', 'alpha', 'train_auroc', 'test_auroc', 'overfit']]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Correlations', y=1.05, size=15)\n",
    "sns.heatmap(metrics_df_for_correlations.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, annot=True)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c. Evaluate how changing some of the parameters effects performance\n",
    "\n",
    "The three things I'd like to evaluate are n_components, alpha and l1_ratio\n",
    "\n",
    "My thoughts, going from easiest to most difficult to evaluate...\n",
    " - alpha: just make the range larger if a lot of queries are at max or min (i.e. at the edge of the gridsearch space\n",
    " - l1_ratio: the two values that we've discussed are 0 and 0.15... just try both for different setups\n",
    " - n_components: try lists of varying size, try functions to auto select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try all combos of:\n",
    "#### k_range = [10, 20, 40, 80, 160, 320, 640]\n",
    "#### alpha_range = [10** x for x in range(-10,10)]\n",
    "#### and l1_ratio = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>261.143</td>\n",
       "      <td>0.347371</td>\n",
       "      <td>0.793946</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.0882634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>160</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.787152</td>\n",
       "      <td>0.707957</td>\n",
       "      <td>0.0707356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      261.143  0.347371    0.793946   0.705682  0.0882634\n",
       "median          137          160       0.1    0.787152   0.707957  0.0707356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 1.27%\n",
      "Median testing Auroc improved by 0.72%\n",
      "Mean overfitting reduced by -1.0%\n",
      "Median overfitting reduced by -1.0%\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_range\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [10, 20, 40, 80, 160, 320, 640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>640</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.833917</td>\n",
       "      <td>0.709258</td>\n",
       "      <td>0.124658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>640</td>\n",
       "      <td>0.769214</td>\n",
       "      <td>0.852768</td>\n",
       "      <td>0.713322</td>\n",
       "      <td>0.0894777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc    overfit\n",
       "mean        256.657          640  0.538429    0.833917   0.709258   0.124658\n",
       "median          137          640  0.769214    0.852768   0.713322  0.0894777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 1.62%\n",
      "Median testing Auroc improved by 1.25%\n",
      "Mean overfitting reduced by -4.6%\n",
      "Median overfitting reduced by -2.8%\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_max. Test if a range is even any better than just the largest number...\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, but maybe not too suprising. Looks like the range as opposed to just the max helps with overfitting but actually hurts with overall accurace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>85.7143</td>\n",
       "      <td>0.494457</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.0814751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>100</td>\n",
       "      <td>0.297229</td>\n",
       "      <td>0.776817</td>\n",
       "      <td>0.687523</td>\n",
       "      <td>0.0524966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      85.7143  0.494457    0.776175     0.6947  0.0814751\n",
       "median          137          100  0.297229    0.776817   0.687523  0.0524966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 0.17%\n",
      "Median testing Auroc improved by -1.33%\n",
      "Mean overfitting reduced by -0.3%\n",
      "Median overfitting reduced by 0.9%\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# l1_ratio\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [50, 100],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>78.5714</td>\n",
       "      <td>2.69206</td>\n",
       "      <td>0.7786</td>\n",
       "      <td>0.70246</td>\n",
       "      <td>0.0761406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774517</td>\n",
       "      <td>0.699582</td>\n",
       "      <td>0.0584197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components    alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      78.5714  2.69206      0.7786    0.70246  0.0761406\n",
       "median          137          100        1    0.774517   0.699582  0.0584197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 0.94%\n",
      "Median testing Auroc improved by -0.12%\n",
      "Mean overfitting reduced by 0.3%\n",
      "Median overfitting reduced by 0.3%\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# alpha_range\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [50, 100],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>94.2857</td>\n",
       "      <td>346141</td>\n",
       "      <td>0.829757</td>\n",
       "      <td>0.763774</td>\n",
       "      <td>0.0659825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>100</td>\n",
       "      <td>55</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.75685</td>\n",
       "      <td>0.0418654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components   alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      94.2857  346141    0.829757   0.763774  0.0659825\n",
       "median          137          100      55    0.830814    0.75685  0.0418654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 7.08%\n",
      "Median testing Auroc improved by 5.61%\n",
      "Mean overfitting reduced by 1.3%\n",
      "Median overfitting reduced by 1.9%\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# alpha_range and l1_ratio\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [50, 100],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>226.286</td>\n",
       "      <td>1.68035</td>\n",
       "      <td>0.777703</td>\n",
       "      <td>0.691562</td>\n",
       "      <td>0.0861411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>160</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.763551</td>\n",
       "      <td>0.669836</td>\n",
       "      <td>0.0685817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components    alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      226.286  1.68035    0.777703   0.691562  0.0861411\n",
       "median          137          160      0.1    0.763551   0.669836  0.0685817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by -0.15%\n",
      "Median testing Auroc improved by -3.10%\n",
      "Mean overfitting reduced by -0.7%\n",
      "Median overfitting reduced by -0.8%\n",
      "Wall time: 19min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# alpha_range and k_range\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [10, 20, 40, 80, 160, 320, 640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>347.714</td>\n",
       "      <td>0.537914</td>\n",
       "      <td>0.825945</td>\n",
       "      <td>0.709964</td>\n",
       "      <td>0.115981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>320</td>\n",
       "      <td>0.768957</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.718275</td>\n",
       "      <td>0.10949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc   overfit\n",
       "mean        256.657      347.714  0.537914    0.825945   0.709964  0.115981\n",
       "median          137          320  0.768957        0.86   0.718275   0.10949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 1.69%\n",
      "Median testing Auroc improved by 1.75%\n",
      "Mean overfitting reduced by -3.7%\n",
      "Median overfitting reduced by -4.8%\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_range and l1_ratio\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [10, 20, 40, 80, 160, 320, 640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>382.286</td>\n",
       "      <td>3.14305e+06</td>\n",
       "      <td>0.851795</td>\n",
       "      <td>0.77483</td>\n",
       "      <td>0.0769651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>320</td>\n",
       "      <td>10</td>\n",
       "      <td>0.868835</td>\n",
       "      <td>0.758737</td>\n",
       "      <td>0.0592118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components        alpha train_auroc test_auroc  \\\n",
       "mean        256.657      382.286  3.14305e+06    0.851795    0.77483   \n",
       "median          137          320           10    0.868835   0.758737   \n",
       "\n",
       "          overfit  \n",
       "mean    0.0769651  \n",
       "median  0.0592118  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 8.18%\n",
      "Median testing Auroc improved by 5.79%\n",
      "Mean overfitting reduced by 0.2%\n",
      "Median overfitting reduced by 0.2%\n",
      "Wall time: 17min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# All three: k_range, alpha_range and l1_ratio\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [10, 20, 40, 80, 160, 320, 640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>640</td>\n",
       "      <td>3.14889e+07</td>\n",
       "      <td>0.870003</td>\n",
       "      <td>0.771827</td>\n",
       "      <td>0.0981763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>640</td>\n",
       "      <td>55</td>\n",
       "      <td>0.872664</td>\n",
       "      <td>0.755183</td>\n",
       "      <td>0.0634218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components        alpha train_auroc test_auroc  \\\n",
       "mean        256.657          640  3.14889e+07    0.870003   0.771827   \n",
       "median          137          640           55    0.872664   0.755183   \n",
       "\n",
       "          overfit  \n",
       "mean    0.0981763  \n",
       "median  0.0634218  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 7.88%\n",
      "Median testing Auroc improved by 5.44%\n",
      "Mean overfitting reduced by -1.9%\n",
      "Median overfitting reduced by -0.2%\n",
      "Wall time: 7min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# All three: k_range, alpha_range and l1_ratio... Again this time only use the max of the k_range\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = [640],\n",
    "                                               k_function = None,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the larger aplha range and l1_ratio it looks like having the range of k as opposed to just the max helps with both overall performance as well as overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a function to automatically select the parameter space to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k_range function\n",
    "def k_func(num_positives):\n",
    "    if num_positives < 50:\n",
    "        k_range = [6, 8, 10, 14, 20, 28]\n",
    "    elif num_positives < 100:\n",
    "        k_range = [10, 15, 20, 30, 50, 80]\n",
    "    elif num_positives < 200:\n",
    "        k_range = [15, 25, 50, 75, 100, 175]\n",
    "    elif num_positives < 500:\n",
    "        k_range = [60, 100, 150, 250, 400] # Tried 30, 60, 100, 150\n",
    "    else:\n",
    "        k_range = [100, 200, 400, 800]\n",
    "    return(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>166.314</td>\n",
       "      <td>0.464371</td>\n",
       "      <td>0.753238</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.0574961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.691246</td>\n",
       "      <td>0.0582237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components     alpha train_auroc test_auroc    overfit\n",
       "mean        256.657      166.314  0.464371    0.753238   0.695742  0.0574961\n",
       "median          137          100       0.1    0.755169   0.691246  0.0582237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 0.27%\n",
      "Median testing Auroc improved by -0.95%\n",
      "Mean overfitting reduced by 2.1%\n",
      "Median overfitting reduced by 0.3%\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_range func\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = None,\n",
    "                                               k_function = k_func,\n",
    "                                               alpha_range = [10** x for x in range(-3, 1)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>169.6</td>\n",
       "      <td>1.4526</td>\n",
       "      <td>0.766604</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.0581044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.705845</td>\n",
       "      <td>0.0491028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components   alpha train_auroc test_auroc    overfit\n",
       "mean        256.657        169.6  1.4526    0.766604     0.7085  0.0581044\n",
       "median          137           80     0.1    0.761007   0.705845  0.0491028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 1.55%\n",
      "Median testing Auroc improved by 0.50%\n",
      "Mean overfitting reduced by 2.1%\n",
      "Median overfitting reduced by 1.2%\n",
      "Wall time: 11min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_range func with larger alpha range\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = None,\n",
    "                                               k_function = k_func,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0.15])\n",
    "display_stats(metrics_df, metrics_df_current_setup, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_comp_status</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_status</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>max</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.771098</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.197024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>OK</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.582438</td>\n",
       "      <td>0.233803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>0.74957</td>\n",
       "      <td>0.0251575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>OK</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.741009</td>\n",
       "      <td>0.702819</td>\n",
       "      <td>0.0381898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>OK</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.768437</td>\n",
       "      <td>0.742946</td>\n",
       "      <td>0.0254908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.926328</td>\n",
       "      <td>0.703114</td>\n",
       "      <td>0.223214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>OK</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.722205</td>\n",
       "      <td>0.587625</td>\n",
       "      <td>0.13458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>OK</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.715819</td>\n",
       "      <td>0.718188</td>\n",
       "      <td>-0.00236926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.0386118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>max</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>max</td>\n",
       "      <td>0.704129</td>\n",
       "      <td>0.706623</td>\n",
       "      <td>-0.00249354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>max</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.728736</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>-0.0325916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>91</td>\n",
       "      <td>50</td>\n",
       "      <td>OK</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.823755</td>\n",
       "      <td>0.67047</td>\n",
       "      <td>0.153284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>104</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>10000000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.70726</td>\n",
       "      <td>0.659344</td>\n",
       "      <td>0.0479152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>112</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.960569</td>\n",
       "      <td>0.957638</td>\n",
       "      <td>0.00293089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>117</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.869715</td>\n",
       "      <td>0.693356</td>\n",
       "      <td>0.176359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>117</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.898487</td>\n",
       "      <td>0.812942</td>\n",
       "      <td>0.0855446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>135</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.991725</td>\n",
       "      <td>0.983379</td>\n",
       "      <td>0.00834692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>136</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.789882</td>\n",
       "      <td>0.725919</td>\n",
       "      <td>0.0639631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.792941</td>\n",
       "      <td>0.716417</td>\n",
       "      <td>0.0765236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>153</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.825144</td>\n",
       "      <td>0.766363</td>\n",
       "      <td>0.058781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>169</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.787689</td>\n",
       "      <td>0.73986</td>\n",
       "      <td>0.047829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>185</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906917</td>\n",
       "      <td>-0.030446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>188</td>\n",
       "      <td>175</td>\n",
       "      <td>max</td>\n",
       "      <td>1000</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.762345</td>\n",
       "      <td>0.747748</td>\n",
       "      <td>0.0145974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>231</td>\n",
       "      <td>250</td>\n",
       "      <td>OK</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.91148</td>\n",
       "      <td>0.853169</td>\n",
       "      <td>0.0583107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>235</td>\n",
       "      <td>400</td>\n",
       "      <td>max</td>\n",
       "      <td>100</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.790046</td>\n",
       "      <td>0.732253</td>\n",
       "      <td>0.0577937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>237</td>\n",
       "      <td>400</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.837864</td>\n",
       "      <td>0.70386</td>\n",
       "      <td>0.134004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>263</td>\n",
       "      <td>400</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.928683</td>\n",
       "      <td>0.872011</td>\n",
       "      <td>0.0566725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>274</td>\n",
       "      <td>400</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.925013</td>\n",
       "      <td>0.874314</td>\n",
       "      <td>0.0506987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>279</td>\n",
       "      <td>400</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.904708</td>\n",
       "      <td>0.838317</td>\n",
       "      <td>0.0663911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>316</td>\n",
       "      <td>250</td>\n",
       "      <td>OK</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.813683</td>\n",
       "      <td>0.788081</td>\n",
       "      <td>0.0256023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>423</td>\n",
       "      <td>150</td>\n",
       "      <td>OK</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.914517</td>\n",
       "      <td>0.877411</td>\n",
       "      <td>0.0371053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>500</td>\n",
       "      <td>800</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.96102</td>\n",
       "      <td>0.952072</td>\n",
       "      <td>0.00894727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>527</td>\n",
       "      <td>400</td>\n",
       "      <td>OK</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.946846</td>\n",
       "      <td>0.0133901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>853</td>\n",
       "      <td>800</td>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.877066</td>\n",
       "      <td>0.862998</td>\n",
       "      <td>0.0140685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>2587</td>\n",
       "      <td>800</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.954474</td>\n",
       "      <td>0.927714</td>\n",
       "      <td>0.0267597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_positive n_components n_comp_status       alpha alpha_status  \\\n",
       "6714           34           28           max        1000           OK   \n",
       "4609           37           20            OK        1000           OK   \n",
       "207            38           28           max         100           OK   \n",
       "5894           42           14            OK        1000           OK   \n",
       "4087           48           14            OK        1000           OK   \n",
       "5604           55           80           max          10           OK   \n",
       "4221           57           30            OK        1000           OK   \n",
       "7490           58           20            OK        1000           OK   \n",
       "4771           79           80           max         100           OK   \n",
       "25             80           80           max  1000000000          max   \n",
       "4921           85           80           max        1000           OK   \n",
       "5159           91           50            OK          10           OK   \n",
       "7486          104          100            OK    10000000           OK   \n",
       "3265          112          175           max          10           OK   \n",
       "5979          117          175           max          10           OK   \n",
       "4893          117          175           max          10           OK   \n",
       "7428          135          175           max       1e-05           OK   \n",
       "672           136          175           max         100           OK   \n",
       "238           138          175           max         100           OK   \n",
       "2064          153          175           max         100           OK   \n",
       "3791          169          175           max         100           OK   \n",
       "4089          185          175           max         100           OK   \n",
       "6098          188          175           max        1000           OK   \n",
       "1956          231          250            OK          10           OK   \n",
       "1630          235          400           max         100           OK   \n",
       "675           237          400           max          10           OK   \n",
       "5925          263          400           max          10           OK   \n",
       "1029          274          400           max          10           OK   \n",
       "5728          279          400           max          10           OK   \n",
       "4763          316          250            OK          10           OK   \n",
       "324           423          150            OK          10           OK   \n",
       "673           500          800           max          10           OK   \n",
       "3845          527          400            OK          10           OK   \n",
       "5290          853          800           max          10           OK   \n",
       "7157         2587          800           max           1           OK   \n",
       "\n",
       "     train_auroc test_auroc     overfit  \n",
       "6714    0.771098   0.574074    0.197024  \n",
       "4609    0.816241   0.582438    0.233803  \n",
       "207     0.774728    0.74957   0.0251575  \n",
       "5894    0.741009   0.702819   0.0381898  \n",
       "4087    0.768437   0.742946   0.0254908  \n",
       "5604    0.926328   0.703114    0.223214  \n",
       "4221    0.722205   0.587625     0.13458  \n",
       "7490    0.715819   0.718188 -0.00236926  \n",
       "4771    0.857419   0.818807   0.0386118  \n",
       "25      0.704129   0.706623 -0.00249354  \n",
       "4921    0.728736   0.761327  -0.0325916  \n",
       "5159    0.823755    0.67047    0.153284  \n",
       "7486     0.70726   0.659344   0.0479152  \n",
       "3265    0.960569   0.957638  0.00293089  \n",
       "5979    0.869715   0.693356    0.176359  \n",
       "4893    0.898487   0.812942   0.0855446  \n",
       "7428    0.991725   0.983379  0.00834692  \n",
       "672     0.789882   0.725919   0.0639631  \n",
       "238     0.792941   0.716417   0.0765236  \n",
       "2064    0.825144   0.766363    0.058781  \n",
       "3791    0.787689    0.73986    0.047829  \n",
       "4089    0.876471   0.906917   -0.030446  \n",
       "6098    0.762345   0.747748   0.0145974  \n",
       "1956     0.91148   0.853169   0.0583107  \n",
       "1630    0.790046   0.732253   0.0577937  \n",
       "675     0.837864    0.70386    0.134004  \n",
       "5925    0.928683   0.872011   0.0566725  \n",
       "1029    0.925013   0.874314   0.0506987  \n",
       "5728    0.904708   0.838317   0.0663911  \n",
       "4763    0.813683   0.788081   0.0256023  \n",
       "324     0.914517   0.877411   0.0371053  \n",
       "673      0.96102   0.952072  0.00894727  \n",
       "3845    0.960236   0.946846   0.0133901  \n",
       "5290    0.877066   0.862998   0.0140685  \n",
       "7157    0.954474   0.927714   0.0267597  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_positive</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.657</td>\n",
       "      <td>223.543</td>\n",
       "      <td>2.88574e+07</td>\n",
       "      <td>0.839741</td>\n",
       "      <td>0.778769</td>\n",
       "      <td>0.0609711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>137</td>\n",
       "      <td>175</td>\n",
       "      <td>100</td>\n",
       "      <td>0.831504</td>\n",
       "      <td>0.755449</td>\n",
       "      <td>0.0478721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_positive n_components        alpha train_auroc test_auroc  \\\n",
       "mean        256.657      223.543  2.88574e+07    0.839741   0.778769   \n",
       "median          137          175          100    0.831504   0.755449   \n",
       "\n",
       "          overfit  \n",
       "mean    0.0609711  \n",
       "median  0.0478721  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean testing Auroc improved by 8.57%\n",
      "Median testing Auroc improved by 5.47%\n",
      "Mean overfitting reduced by 1.8%\n",
      "Median overfitting reduced by 1.3%\n",
      "Wall time: 10min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k_range func with larger alpha range and l1_ratio = 0\n",
    "metrics_df = evaluate_classifier(X_train = X_train,\n",
    "                                               X_test = X_test,\n",
    "                                               y = y,\n",
    "                                               y_train_allgenes = y_train_allgenes,\n",
    "                                               y_test_allgenes = y_test_allgenes,\n",
    "                                               list_of_genes = list_of_genes,\n",
    "                                               set_k_range = None,\n",
    "                                               k_function = k_func,\n",
    "                                               alpha_range = [10** x for x in range(-10, 10)],\n",
    "                                               l1_ratio = [0])\n",
    "display_stats(metrics_df, metrics_df_current_setup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
